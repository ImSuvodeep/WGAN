{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d18473",
      "metadata": {
        "id": "c4d18473",
        "outputId": "794c3a29-ec40-4dc9-bb07-c0d3688a0042"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\suvod\\Anaconda\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "# importing the libraries\n",
        "import torch, torchvision, os, PIL, pdb\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show(tensor, num=25, wandbactive=0, name=''):\n",
        "  data = tensor.detach().cpu()\n",
        "  grid = make_grid(data[:num], nrow=5).permute(1,2,0)\n",
        "\n",
        "  ## optional\n",
        "  if (wandbactive==1):\n",
        "    wandb.log({name:wandb.Image(grid.numpy().clip(0,1))})\n",
        "\n",
        "  plt.imshow(grid.clip(0,1))\n",
        "  plt.show()\n",
        "\n",
        "### hyperparameters and general parameters\n",
        "n_epochs=10000\n",
        "batch_size=128\n",
        "lr=1e-4\n",
        "z_dim=200\n",
        "device='cuda' #GPU\n",
        "\n",
        "cur_step=0\n",
        "crit_cycles=5\n",
        "gen_losses=[]\n",
        "crit_losses=[]\n",
        "show_step=35\n",
        "save_step=35\n",
        "\n",
        "wandbact=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34ec3d4d",
      "metadata": {
        "id": "34ec3d4d",
        "outputId": "0d28b416-eb8d-4d3f-d4e2-e8d122b3d01e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msuvodeepchowdhury108\u001b[0m (\u001b[33mpersonall-projects\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\suvod/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#### optional\n",
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "\n",
        "wandb.login(key='108ce43c699626ffceae7d5b1d1a779f9dfae981')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68b1b5ee",
      "metadata": {
        "id": "68b1b5ee"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "experiment_name = wandb.util.generate_id()\n",
        "\n",
        "myrun=wandb.init(\n",
        "    project=\"wgan\",\n",
        "    group=experiment_name,\n",
        "    config={\n",
        "        \"optimizer\":\"adam\",\n",
        "        \"model\":\"wgan gp\",\n",
        "        \"epoch\":\"1000\",\n",
        "        \"batch_size\":128\n",
        "    }\n",
        ")\n",
        "\n",
        "config=wandb.config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa712b8",
      "metadata": {
        "id": "6fa712b8"
      },
      "outputs": [],
      "source": [
        "# generator model\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self,z_dim =64, h_dim = 16):\n",
        "        super(Generator,self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.gen  = nn.Sequential(\n",
        "\n",
        "            nn.ConvTranspose2d(z_dim ,h_dim * 32, 4,2,0),\n",
        "            nn.BatchNorm2d(h_dim * 32),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(h_dim * 32, h_dim * 16, 4,2,1),\n",
        "            nn.BatchNorm2d(h_dim * 16),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(h_dim * 16, h_dim * 8, 4,2,1),\n",
        "            nn.BatchNorm2d(h_dim * 8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(h_dim * 8, h_dim * 4, 4,2,1),\n",
        "            nn.BatchNorm2d(h_dim * 4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(h_dim * 4, h_dim * 2,4,2,1),\n",
        "            nn.BatchNorm2d(h_dim * 2),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(h_dim * 2, 3,4,2,1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self,nosie):\n",
        "        x = noise.view(len(noise),self.z_dim, 1,1)\n",
        "        return self.gen(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a5666da",
      "metadata": {
        "id": "4a5666da"
      },
      "outputs": [],
      "source": [
        "def genNoise(num,z_dim ):\n",
        "    return torch.randn(num,z_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6506a403",
      "metadata": {
        "id": "6506a403"
      },
      "outputs": [],
      "source": [
        "## critic model\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self,h_dim  = 16):\n",
        "        super(Critic,self).__init__()\n",
        "        self.crit = nn.Sequential(\n",
        "            nn.Conv2d(3, h_dim, 4,2,1),\n",
        "            nn.BatchNorm2d(h_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "\n",
        "            nn.Conv2d(h_dim, h_dim * 2, 4,2,1),\n",
        "            nn.BatchNorm2d(h_dim * 2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(h_dim * 2, h_dim * 4, 4,2,1),\n",
        "            nn.BatchNorm2d(h_dim * 4),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(h_dim * 4, h_dim * 8 , 4,2,1),\n",
        "            nn.BatchNorm2d(h_dim * 8),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(h_dim * 8, h_dim * 16,4,2,1),\n",
        "            nn.BatchNorm2d(h_dim * 16),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(h_dim * 16, 1,4,2,0)\n",
        "        )\n",
        "\n",
        "    def forward(self,image):\n",
        "        crit_pred = self.crit(image)\n",
        "        return crit_pred.view(len(crit_pred),-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6b1a2c2",
      "metadata": {
        "id": "e6b1a2c2"
      },
      "outputs": [],
      "source": [
        "## optional, init your weights in different ways\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        torch.nn.init.normal_(m.weights, 0.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bais, 0)\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weights, 0.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bais, 0)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e11db1",
      "metadata": {
        "id": "15e11db1"
      },
      "outputs": [],
      "source": [
        "### Dataset, DataLoader, declare gen,crit, test dataset\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self,path,size = 128, lim = 10000):\n",
        "        self.sizes = [size,size]\n",
        "        items,labels = [] , []\n",
        "\n",
        "        for data in os.listdir(path)[:lim]:\n",
        "            item = os.path.join(path,data)\n",
        "            items.append(item)\n",
        "            labels.append(data)\n",
        "        self.items = items\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        data = PIL.Image.open(self.items[idx]).convert('RGB')\n",
        "        data = np.asarray(torchvision.transforms.Resize(self.sizes)(data))\n",
        "        data = np.transpose(data, (2,0,1)).astype(np.float32, copy = False)\n",
        "        data = torch.from_numpy(data).div(255)\n",
        "        return data, self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c668d3e2",
      "metadata": {
        "scrolled": true,
        "id": "c668d3e2"
      },
      "outputs": [],
      "source": [
        "## Dataset path\n",
        "extracted_folder_path = r\"C:\\Users\\suvod\\Downloads\\img_align_celeba (4)\\img_align_celeba\"\n",
        "ds = Dataset(extracted_folder_path, size = 128, lim = 10000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "829284e6",
      "metadata": {
        "id": "829284e6"
      },
      "outputs": [],
      "source": [
        "## DataLoader\n",
        "dataloader = DataLoader(ds,batch_size = batch_size,shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "810a472c",
      "metadata": {
        "id": "810a472c"
      },
      "outputs": [],
      "source": [
        "## Models\n",
        "gen = Generator(z_dim)\n",
        "crit = Critic()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "358f9f0d",
      "metadata": {
        "id": "358f9f0d"
      },
      "outputs": [],
      "source": [
        "## Optimizers\n",
        "gen_opt = torch.optim.Adam(gen.parameters() , lr=lr, betas = (0.5,0.9))\n",
        "crit_opt = torch.optim.Adam(crit.parameters() , lr = lr , betas = (0.5, 0.9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca9ffe84",
      "metadata": {
        "id": "ca9ffe84"
      },
      "outputs": [],
      "source": [
        "## gradient penalty calculation\n",
        "\n",
        "def get_gp(real,fake,crit,alpha,gamma = 10):\n",
        "    mix_images = real * alpha + fake * (1-alpha)\n",
        "    mix_scores = crit(mix_images)\n",
        "\n",
        "    gradient = torch.autograd.grad(\n",
        "        inputs = mix_images,\n",
        "        outputs = mix_scores,\n",
        "        grad_outputs = torch.ones_like(mix_scores),\n",
        "        retain_graph = True,\n",
        "        create_graph = True,\n",
        "    )[0]\n",
        "\n",
        "    gradient = gradient.view(len(gradient),-1)\n",
        "    gp_norm = gradient.norm(2, dim = 1)\n",
        "    gp = gamma *((gp_norm - 1) ** 2).mean()\n",
        "    return gp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7829b225",
      "metadata": {
        "id": "7829b225"
      },
      "outputs": [],
      "source": [
        "## Save checkpoints\n",
        "root_path = './data/'\n",
        "def save_checkpoint(name):\n",
        "\n",
        "    torch.save({\n",
        "        'epoch':epoch,\n",
        "        'model_state_dict':gen.state_dict(),\n",
        "        'optimizer_state_dict': gen_opt.state_dict(),\n",
        "    },f'{root_path}G-{name}.pkl')\n",
        "\n",
        "    torch.save({\n",
        "        'epoch':epoch,\n",
        "        'model_state_dict':crit.state_dict(),\n",
        "        'optimizer_state_dict': crit_opt.state_dict(),\n",
        "    },f'{root_path}C-{name}.pkl')\n",
        "\n",
        "    print(\"Saving Checkpoint\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb795d09",
      "metadata": {
        "id": "cb795d09"
      },
      "outputs": [],
      "source": [
        "#Load checkpoints\n",
        "def load_checkpoint(name):\n",
        "    checkpoint = torch.load(f'{root_path}G-{name}.pkl')\n",
        "    gen.load_state_dict(checkpoint['model_state_dict'])\n",
        "    gen_opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    chekcpoint = torch.load(f'{root_path}C-{name}.pkl')\n",
        "    crit.load_state_dict(checkpoint['model_state_dict'])\n",
        "    crit_opt.load_state_dict(checkpointnt['optimizer_state_dict'])\n",
        "\n",
        "    print('Loading Checkpoint')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3f8046b",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "9373ba4c94b1466d92f0184d72b60ec5",
            "9e4b51dc00b6402094f66dc71f2bdd82",
            "46baa1139dc74a9eb7e298eb3664498e",
            "fadb484b641145a4a2d7806dbcefeffd",
            "6e50b7042d384d10853519386a36b3a9",
            "cd6dea34ae124530aac0aeecbbeb330b",
            "a2a28bf9ddfa44559987e673b7a970f3",
            "2dec6d2ad4f54779b0788717a4fd1a00",
            "44aa77fc449344108d81fdced19cae67"
          ]
        },
        "id": "f3f8046b",
        "outputId": "4d7a9ef9-28c6-4b49-e567-627660e90339"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9373ba4c94b1466d92f0184d72b60ec5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e4b51dc00b6402094f66dc71f2bdd82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46baa1139dc74a9eb7e298eb3664498e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fadb484b641145a4a2d7806dbcefeffd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e50b7042d384d10853519386a36b3a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd6dea34ae124530aac0aeecbbeb330b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2a28bf9ddfa44559987e673b7a970f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dec6d2ad4f54779b0788717a4fd1a00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44aa77fc449344108d81fdced19cae67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "## Training loop\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for real,_ in tqdm(dataloader):\n",
        "        cur_bs = len(real)\n",
        "\n",
        "        ### CRITIC\n",
        "        mean_crit_loss = 0\n",
        "        for _ in range(crit_cycles):\n",
        "            crit_opt.zero_grad()\n",
        "\n",
        "            noise = genNoise(cur_bs,z_dim)\n",
        "            fake = gen(noise)\n",
        "            crit_pred_fake = crit(fake.detach())\n",
        "            crit_pred_real = crit(real)\n",
        "\n",
        "            alpha = torch.rand(len(real),1,1,1,device = \"cpu\",requires_grad = True)\n",
        "            gp = get_gp(real,fake.detach(),crit,alpha)\n",
        "\n",
        "            crit_loss = crit_pred_fake.mean() - crit_pred_real.mean() + gp\n",
        "            mean_crit_loss += crit_loss.item() / crit_cycles\n",
        "\n",
        "\n",
        "            crit_loss.backward(retain_graph = True)\n",
        "            crit_opt.step()\n",
        "        crit_losses += [mean_crit_loss]\n",
        "\n",
        "        ### GENERATOR\n",
        "        gen_opt.zero_grad()\n",
        "        noise = genNoise(cur_bs, z_dim)\n",
        "        fake = gen(noise)\n",
        "        crit_fake_pred = crit(fake)\n",
        "\n",
        "        gen_loss = -crit_fake_pred.mean()\n",
        "        gen_loss.backward()\n",
        "        gen_opt.step()\n",
        "\n",
        "        gen_losses += [gen_loss.item()]\n",
        "\n",
        "\n",
        "        ### Stats\n",
        "\n",
        "        if (wandbact==1):\n",
        "          wandb.log({'Epoch': epoch, 'Step': cur_step, 'Critic loss':mean_crit_loss, 'Gen loss': gen_loss})\n",
        "\n",
        "        if cur_step % save_step == 0 and cur_step > 0:\n",
        "          print(\"Saving checkpoint: \", cur_step, save_step)\n",
        "          save_checkpoint(\"latest\")\n",
        "\n",
        "        if (cur_step % show_step == 0 and cur_step > 0):\n",
        "          show(fake, wandbactive=1, name='fake')\n",
        "          show(real, wandbactive=1, name='real')\n",
        "\n",
        "          gen_mean=sum(gen_losses[-show_step:]) / show_step\n",
        "          crit_mean = sum(crit_losses[-show_step:]) / show_step\n",
        "          print(f\"Epoch: {epoch}: Step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\")\n",
        "\n",
        "          plt.plot(\n",
        "              range(len(gen_losses)),\n",
        "              torch.Tensor(gen_losses),\n",
        "              label=\"Generator Loss\"\n",
        "          )\n",
        "\n",
        "          plt.plot(\n",
        "              range(len(gen_losses)),\n",
        "              torch.Tensor(crit_losses),\n",
        "              label=\"Critic Loss\"\n",
        "          )\n",
        "\n",
        "          plt.ylim(-150,150)\n",
        "          plt.legend()\n",
        "          plt.show()\n",
        "\n",
        "    cur_step+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c08cb14f",
      "metadata": {
        "id": "c08cb14f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0765162f",
      "metadata": {
        "id": "0765162f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}